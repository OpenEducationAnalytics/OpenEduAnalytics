{
  "nbformat": 4,
  "nbformat_minor": 2,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Learning Analytics v2\r\n",
        "\r\n",
        "## Learning Resources Schema Fact Tables\r\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": null,
              "session_id": "44",
              "statement_id": -1,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2023-07-05T15:49:23.3747343Z",
              "session_start_time": null,
              "execution_start_time": "2023-07-05T15:52:48.011038Z",
              "execution_finish_time": "2023-07-05T15:52:48.0112543Z",
              "spark_jobs": null,
              "parent_msg_id": "d900c744-0d01-48ac-87cc-083f25f238ed"
            },
            "text/plain": "StatementMeta(, 44, -1, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "2023-07-05 15:52:47,541 - OEA - INFO - Now using workspace: dev\n2023-07-05 15:52:47,542 - OEA - INFO - OEA initialized.\n"
        }
      ],
      "metadata": {},
      "source": [
        "%run OEA_py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "spark3p3sm",
              "session_id": "44",
              "statement_id": 3,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2023-07-05T15:49:23.3824097Z",
              "session_start_time": null,
              "execution_start_time": "2023-07-05T15:52:48.1743029Z",
              "execution_finish_time": "2023-07-05T15:52:48.3453279Z",
              "spark_jobs": null,
              "parent_msg_id": "0350fe9f-3066-48d4-9c95-fac59d957ec4"
            },
            "text/plain": "StatementMeta(spark3p3sm, 44, 3, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "2023-07-05 15:52:48,143 - OEA - INFO - Now using workspace: dev\n"
        }
      ],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "workspace = 'dev'\r\n",
        "oea.set_workspace(workspace)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "spark3p3sm",
              "session_id": "44",
              "statement_id": 4,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2023-07-05T15:49:23.3834221Z",
              "session_start_time": null,
              "execution_start_time": "2023-07-05T15:52:48.5050496Z",
              "execution_finish_time": "2023-07-05T15:52:48.7030854Z",
              "spark_jobs": null,
              "parent_msg_id": "a2728dab-7615-4a64-bd15-f47214773a6f"
            },
            "text/plain": "StatementMeta(spark3p3sm, 44, 4, Finished, Available)"
          },
          "metadata": {}
        }
      ],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "from pyspark.sql.functions import col, lit, split\r\n",
        "from pyspark.sql import functions as f\r\n",
        "import os\r\n",
        "import uuid\r\n",
        "\r\n",
        "# helper functions\r\n",
        "def _publish_to_stage2(df, destination, pk):\r\n",
        "    oea.upsert(df, destination, pk)\r\n",
        "\r\n",
        "def publish(df, stage2_destination, stage3_destination, primary_key='id'):\r\n",
        "    _publish_to_stage2(df, stage2_destination, primary_key)\r\n",
        "\r\n",
        "    spark.sql(\"set spark.sql.streaming.schemaInference=true\")\r\n",
        "    streaming_df = spark.readStream.format('delta').load(oea.to_url(stage2_destination))\r\n",
        "    # for more info on append vs complete vs update modes for structured streaming: https://spark.apache.org/docs/latest/structured-streaming-programming-guide.html#basic-concepts\r\n",
        "    query = streaming_df.writeStream.format('delta').outputMode('append').trigger(once=True).option('checkpointLocation', oea.to_url(stage2_destination) + '/_checkpoints')\r\n",
        "    query = query.start(oea.to_url(stage3_destination))\r\n",
        "    query.awaitTermination()   # block until query is terminated, with stop() or with error; A StreamingQueryException will be thrown if an exception occurs.\r\n",
        "    number_of_new_inbound_rows = query.lastProgress[\"numInputRows\"]\r\n",
        "    logger.info(f'Number of new inbound rows processed: {number_of_new_inbound_rows}')\r\n",
        "    logger.debug(query.lastProgress)\r\n",
        "    return number_of_new_inbound_rows\r\n",
        "\r\n",
        "def format_to_schema(df, column_mapping, schema, source_directory):\r\n",
        "    \"\"\" This funciton formats a dataframe to match a schema dataframe format. \r\n",
        "        Column mapping needs to be provided. If columns are missing, they are filled as none type.\r\n",
        "    \"\"\"\r\n",
        "    \r\n",
        "    # rename columns\r\n",
        "    dfSource = df.select([col(existing_col).alias(column_mapping[existing_col]) for existing_col in df.columns])\r\n",
        "    data_source = source_directory.split(os.path.sep)[2]\r\n",
        "    dfSource = dfSource.withColumn(\"data_source\", lit(data_source))\r\n",
        "    dfSource = dfSource.withColumn(\"source_directory\", lit(source_directory)) \r\n",
        "\r\n",
        "    # create missing columns with needed data type\r\n",
        "    missing_columns = [col for col in schema.names if col not in dfSource.columns]\r\n",
        "    for column in missing_columns:\r\n",
        "        dfSource = dfSource.withColumn(column, lit(None).cast(schema[column].dataType))\r\n",
        "\r\n",
        "    dfSource = dfSource.select(schema.names) # ensure column order matches\r\n",
        "\r\n",
        "    return dfSource"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "spark3p3sm",
              "session_id": "44",
              "statement_id": 5,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2023-07-05T15:49:23.3843931Z",
              "session_start_time": null,
              "execution_start_time": "2023-07-05T15:52:48.8836194Z",
              "execution_finish_time": "2023-07-05T15:52:50.5678047Z",
              "spark_jobs": null,
              "parent_msg_id": "4d2543b4-8493-485d-8a42-7caaf8a6fcad"
            },
            "text/plain": "StatementMeta(spark3p3sm, 44, 5, Finished, Available)"
          },
          "metadata": {}
        }
      ],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "column_names = ['id', 'source_resource_activity_id', 'resource_id', 'user_id_pseudonym', 'attempt_number',\r\n",
        "                    'attempt_grade', 'attempt_state', 'time_start', 'time_finish', 'data_source', 'source_directory']\r\n",
        "schema = StructType([StructField(name, StringType(), nullable=True) for name in column_names])\r\n",
        "dfFactResourceActivity = spark.createDataFrame([], schema)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "spark3p3sm",
              "session_id": "44",
              "statement_id": 6,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2023-07-05T15:49:23.3854163Z",
              "session_start_time": null,
              "execution_start_time": "2023-07-05T15:52:50.7547648Z",
              "execution_finish_time": "2023-07-05T15:53:27.096946Z",
              "spark_jobs": null,
              "parent_msg_id": "553e333a-ec3c-4c6a-a8ba-dfb9827b40b1"
            },
            "text/plain": "StatementMeta(spark3p3sm, 44, 6, Finished, Available)"
          },
          "metadata": {}
        }
      ],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# load resource dim table to lookup resource ids\r\n",
        "source_directory = 'stage2/Enriched/learning_analytics/v2.0/general/dim_resource'\r\n",
        "dfDimResource = oea.load(source_directory)\r\n",
        "dfDimResource = dfDimResource.select(['id','source_resource_id','resource_type', 'data_source'])\r\n",
        "dfDimResource = dfDimResource.withColumnRenamed(\"id\", \"resource_id\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "spark3p3sm",
              "session_id": "44",
              "statement_id": 7,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2023-07-05T15:49:23.3864535Z",
              "session_start_time": null,
              "execution_start_time": "2023-07-05T15:53:27.2713046Z",
              "execution_finish_time": "2023-07-05T15:53:38.7836461Z",
              "spark_jobs": null,
              "parent_msg_id": "110fc842-6ab8-42e3-aa07-b753a7775221"
            },
            "text/plain": "StatementMeta(spark3p3sm, 44, 7, Finished, Available)"
          },
          "metadata": {}
        }
      ],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "collapsed": false
      },
      "source": [
        "# moodle quiz_attempts learning resource activity data\r\n",
        "source_directory = 'stage2/Refined/moodle/v4.1/general/quiz_attempts'\r\n",
        "dfQuizAttempts = oea.load(source_directory)\r\n",
        "\r\n",
        "dfQuizAttempts = dfQuizAttempts.select(['id','quiz', 'userid_pseudonym', 'attempt', 'sumgrades', \r\n",
        "                            'state', 'timestart', 'timefinish'])\r\n",
        "\r\n",
        "# find resource idea via dim_resource DeltaTable\r\n",
        "dfResourceLookup = dfDimResource.filter((col(\"resource_type\") == \"quiz\") & \r\n",
        "                                        (col(\"data_source\") == \"moodle\"))\r\n",
        "dfQuizAttempts = dfResourceLookup.join(dfQuizAttempts, \r\n",
        "                dfResourceLookup[\"source_resource_id\"] == dfQuizAttempts[\"quiz\"])\r\n",
        "dfQuizAttempts = dfQuizAttempts.drop(\"source_resource_id\", \"quiz\", \r\n",
        "                                    \"resource_type\", \"data_source\")\r\n",
        "\r\n",
        "column_mapping = {'id': 'source_resource_activity_id', 'resource_id': 'resource_id', 'userid_pseudonym': 'user_id_pseudonym', \r\n",
        "            'attempt': 'attempt_number', 'sumgrades': 'attempt_grade','state': 'attempt_state',\r\n",
        "            'timestart': 'time_start','timefinish': 'time_finish'}\r\n",
        "\r\n",
        "dfSource = format_to_schema(dfQuizAttempts, column_mapping, dfFactResourceActivity.schema, source_directory)           \r\n",
        "\r\n",
        "dfFactResourceActivity = dfFactResourceActivity.union(dfSource)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "spark3p3sm",
              "session_id": "44",
              "statement_id": 8,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2023-07-05T15:49:23.389088Z",
              "session_start_time": null,
              "execution_start_time": "2023-07-05T15:53:38.9359506Z",
              "execution_finish_time": "2023-07-05T15:53:42.3912854Z",
              "spark_jobs": null,
              "parent_msg_id": "e0b057e1-f571-43de-874e-e19bef477f73"
            },
            "text/plain": "StatementMeta(spark3p3sm, 44, 8, Finished, Available)"
          },
          "metadata": {}
        }
      ],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# moodle assign_submission learning resource activity data\r\n",
        "source_directory =  'stage2/Refined/moodle/v4.1/general/assign_submission'\r\n",
        "dfAssignmentSubmissions = oea.load(source_directory)\r\n",
        "\r\n",
        "dfAssignmentSubmissions = dfAssignmentSubmissions.select(['id','assignment', 'userid_pseudonym', 'attemptnumber', \r\n",
        "                        'status', 'timestarted', 'timecreated'])\r\n",
        "\r\n",
        "# find resource idea via dim_resource DeltaTable\r\n",
        "dfResourceLookup = dfDimResource.filter((col(\"resource_type\") == \"assignment\") & \r\n",
        "                                        (col(\"data_source\") == \"moodle\"))\r\n",
        "dfAssignmentSubmissions = dfResourceLookup.join(dfAssignmentSubmissions, \r\n",
        "                dfResourceLookup[\"source_resource_id\"] == dfAssignmentSubmissions[\"assignment\"])\r\n",
        "dfAssignmentSubmissions = dfAssignmentSubmissions.drop(\"source_resource_id\", \"assignment\", \r\n",
        "                                    \"resource_type\", \"data_source\")\r\n",
        "\r\n",
        "column_mapping = {'id': 'source_resource_activity_id', 'resource_id': 'resource_id', 'userid_pseudonym': 'user_id_pseudonym', \r\n",
        "            'attemptnumber': 'attempt_number', 'status': 'attempt_state',\r\n",
        "            'timestarted': 'time_start','timecreated': 'time_finish'}\r\n",
        "dfSource = format_to_schema(dfAssignmentSubmissions, column_mapping, dfFactResourceActivity.schema, source_directory)           \r\n",
        "\r\n",
        "dfFactResourceActivity = dfFactResourceActivity.union(dfSource)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "spark3p3sm",
              "session_id": "44",
              "statement_id": 9,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2023-07-05T15:49:23.3907896Z",
              "session_start_time": null,
              "execution_start_time": "2023-07-05T15:53:42.578508Z",
              "execution_finish_time": "2023-07-05T15:53:48.13283Z",
              "spark_jobs": null,
              "parent_msg_id": "87c9c11b-da7a-4dca-9f31-ff41ddd93f4b"
            },
            "text/plain": "StatementMeta(spark3p3sm, 44, 9, Finished, Available)"
          },
          "metadata": {}
        }
      ],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "collapsed": false
      },
      "source": [
        "# moodle lesson_attempts learning resource activity data\r\n",
        "df1 = oea.load('stage2/Refined/moodle/v4.1/general/lesson_attempts')\r\n",
        "subset_columns = ['id','lessonid','userid_pseudonym','correct']\r\n",
        "df1 = df1.select(subset_columns)\r\n",
        "df1 = df1.withColumnRenamed('lessonid', 'lesson_id')\r\n",
        "df1 = df1.withColumnRenamed('userid_pseudonym', 'user_id_pseudonym')\r\n",
        "df1 = df1.withColumnRenamed('correct', 'attempt_grade')\r\n",
        "\r\n",
        "df2 = oea.load('stage2/Refined/moodle/v4.1/general/lesson_timer')\r\n",
        "subset_columns = ['lessonid','userid_pseudonym','completed','starttime','lessontime']\r\n",
        "df2 = df2.select(subset_columns)\r\n",
        "df2 = df2.withColumnRenamed('lessonid', 'lesson_id')\r\n",
        "df2 = df2.withColumnRenamed('userid_pseudonym', 'user_id_pseudonym')\r\n",
        "df2 = df2.withColumnRenamed('completed', 'attempt_state')\r\n",
        "df2 = df2.withColumnRenamed('starttime', 'time_start')\r\n",
        "df2 = df2.withColumnRenamed('lessontime', 'time_finish')\r\n",
        "\r\n",
        "# Subset the DataFrame by earliest start date and latest end date for each user ID and lesson ID\r\n",
        "earliest_start_dates = df2.groupBy(\"user_id_pseudonym\", \"lesson_id\").agg(f.min(\"time_start\").alias(\"earliest_time_start\"))\r\n",
        "latest_end_dates = df2.groupBy(\"user_id_pseudonym\", \"lesson_id\").agg(f.max(\"time_finish\").alias(\"latest_time_finish\"))\r\n",
        "\r\n",
        "dfResult = earliest_start_dates.join(latest_end_dates, [\"user_id_pseudonym\", \"lesson_id\"], \"inner\")\r\n",
        "dfResult = dfResult.withColumnRenamed('earliest_time_start', 'time_start')\r\n",
        "dfResult = dfResult.withColumnRenamed('latest_time_finish', 'time_finish')\r\n",
        "\r\n",
        "dfLessonAttempts = df1.join(dfResult, [\"user_id_pseudonym\", \"lesson_id\"], how='left')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "spark3p3sm",
              "session_id": "44",
              "statement_id": 10,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2023-07-05T15:49:23.3923165Z",
              "session_start_time": null,
              "execution_start_time": "2023-07-05T15:53:48.2909441Z",
              "execution_finish_time": "2023-07-05T15:53:48.4733397Z",
              "spark_jobs": null,
              "parent_msg_id": "130ed66d-cadd-447f-88d2-9c8b686987e8"
            },
            "text/plain": "StatementMeta(spark3p3sm, 44, 10, Finished, Available)"
          },
          "metadata": {}
        }
      ],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# moodle lesson_attempts learning resource activity data\r\n",
        "\r\n",
        "# find resource idea via dim_resource DeltaTable\r\n",
        "dfResourceLookup = dfDimResource.filter((col(\"resource_type\") == \"lesson\") & \r\n",
        "                                        (col(\"data_source\") == \"moodle\"))\r\n",
        "dfLessonAttempts = dfResourceLookup.join(dfLessonAttempts, \r\n",
        "                dfResourceLookup[\"source_resource_id\"] == dfLessonAttempts[\"lesson_id\"])\r\n",
        "dfLessonAttempts = dfLessonAttempts.drop(\"source_resource_id\", \"lesson_id\", \r\n",
        "                                    \"resource_type\", \"data_source\")\r\n",
        "\r\n",
        "column_mapping = {'id': 'source_resource_activity_id', 'resource_id': 'resource_id', 'user_id_pseudonym': 'user_id_pseudonym', \r\n",
        "            'attempt_grade': 'attempt_grade', 'time_start': 'time_start','time_finish': 'time_finish'}\r\n",
        "dfSource = format_to_schema(dfLessonAttempts, column_mapping, dfFactResourceActivity.schema, source_directory)           \r\n",
        "\r\n",
        "dfFactResourceActivity = dfFactResourceActivity.union(dfSource)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "spark3p3sm",
              "session_id": "44",
              "statement_id": 12,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2023-07-05T15:58:06.0991896Z",
              "session_start_time": null,
              "execution_start_time": "2023-07-05T15:58:06.259186Z",
              "execution_finish_time": "2023-07-05T15:58:06.828841Z",
              "spark_jobs": null,
              "parent_msg_id": "eab3bf4c-c0a1-4f03-8b66-1fd5b0926b5b"
            },
            "text/plain": "StatementMeta(spark3p3sm, 44, 12, Finished, Available)"
          },
          "metadata": {}
        }
      ],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# canvas submissions learning resource activity data\r\n",
        "source_directory =  'stage2/Refined/canvas/v2.0/general/submissions'\r\n",
        "dfAssignmentSubmissions = oea.load(source_directory)\r\n",
        "\r\n",
        "dfAssignmentSubmissions = dfAssignmentSubmissions.select(['id','user_id_pseudonym', 'assignment_id', \r\n",
        "                        'attempt', 'published_score', 'workflow_state', 'created_at', 'submitted_at'])\r\n",
        "\r\n",
        "# find resource id via dim_resource DeltaTable\r\n",
        "dfResourceLookup = dfDimResource.filter((col(\"resource_type\") == \"assignment\") & \r\n",
        "                                        (col(\"data_source\") == \"canvas\"))\r\n",
        "dfAssignmentSubmissions = dfResourceLookup.join(dfAssignmentSubmissions, \r\n",
        "                dfResourceLookup[\"source_resource_id\"] == dfAssignmentSubmissions[\"assignment_id\"])\r\n",
        "dfAssignmentSubmissions = dfAssignmentSubmissions.drop(\"source_resource_id\", \"assignment_id\",\r\n",
        "                                    \"resource_type\", \"data_source\")\r\n",
        "\r\n",
        "column_mapping = {'id': 'source_resource_activity_id', 'resource_id': 'resource_id', 'user_id_pseudonym': 'user_id_pseudonym', \r\n",
        "            'attempt': 'attempt_number', 'published_score': 'attempt_grade','workflow_state': 'attempt_state',\r\n",
        "            'created_at': 'time_start','submitted_at': 'time_finish'}\r\n",
        "dfSource = format_to_schema(dfAssignmentSubmissions, column_mapping, dfFactResourceActivity.schema, source_directory)           \r\n",
        "\r\n",
        "dfFactResourceActivity = dfFactResourceActivity.union(dfSource)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "spark3p3sm",
              "session_id": "44",
              "statement_id": 14,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2023-07-05T15:58:43.5798578Z",
              "session_start_time": null,
              "execution_start_time": "2023-07-05T15:58:43.7259596Z",
              "execution_finish_time": "2023-07-05T15:58:44.2896864Z",
              "spark_jobs": null,
              "parent_msg_id": "a5d4818c-baa9-4b2d-b842-b38a871b76f0"
            },
            "text/plain": "StatementMeta(spark3p3sm, 44, 14, Finished, Available)"
          },
          "metadata": {}
        }
      ],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# canvas quiz_submissions learning resource activity data\r\n",
        "source_directory = 'stage2/Refined/canvas/v2.0/general/quiz_submissions'\r\n",
        "dfQuizAttempts = oea.load(source_directory)\r\n",
        "\r\n",
        "dfQuizAttempts = dfQuizAttempts.select(['id','user_id_pseudonym', 'quiz_id', 'attempt', 'kept_score', \r\n",
        "                            'workflow_state', 'started_at', 'finished_at'])\r\n",
        "\r\n",
        "# find resource idea via dim_resource DeltaTable\r\n",
        "dfResourceLookup = dfDimResource.filter((col(\"resource_type\") == \"quiz\") & \r\n",
        "                                        (col(\"data_source\") == \"canvas\"))\r\n",
        "dfQuizAttempts = dfResourceLookup.join(dfQuizAttempts, \r\n",
        "                dfResourceLookup[\"source_resource_id\"] == dfQuizAttempts[\"quiz_id\"])\r\n",
        "dfQuizAttempts = dfQuizAttempts.drop(\"source_resource_id\", \"quiz_id\", \r\n",
        "                                    \"resource_type\", \"data_source\")\r\n",
        "\r\n",
        "column_mapping = {'id': 'source_resource_activity_id', 'resource_id': 'resource_id', 'user_id_pseudonym': 'user_id_pseudonym', \r\n",
        "            'attempt': 'attempt_number', 'kept_score': 'attempt_grade','workflow_state': 'attempt_state',\r\n",
        "            'started_at': 'time_start', 'finished_at': 'time_finish'}\r\n",
        "\r\n",
        "dfSource = format_to_schema(dfQuizAttempts, column_mapping, dfFactResourceActivity.schema, source_directory)           \r\n",
        "\r\n",
        "dfFactResourceActivity = dfFactResourceActivity.union(dfSource)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "spark3p3sm",
              "session_id": "44",
              "statement_id": 15,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2023-07-05T15:58:48.4028969Z",
              "session_start_time": null,
              "execution_start_time": "2023-07-05T15:58:48.556972Z",
              "execution_finish_time": "2023-07-05T15:58:48.7361994Z",
              "spark_jobs": null,
              "parent_msg_id": "56fad25d-5e9f-40e2-b71d-b1bf55401c2e"
            },
            "text/plain": "StatementMeta(spark3p3sm, 44, 15, Finished, Available)"
          },
          "metadata": {}
        }
      ],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# generate uuid\r\n",
        "uuid_udf = f.udf(lambda : str(uuid.uuid4().hex), StringType())\r\n",
        "dfFactResourceActivity = dfFactResourceActivity.withColumn('id', uuid_udf())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "spark3p3sm",
              "session_id": "44",
              "statement_id": 16,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2023-07-05T15:58:50.6611707Z",
              "session_start_time": null,
              "execution_start_time": "2023-07-05T15:58:50.814851Z",
              "execution_finish_time": "2023-07-05T15:59:30.6288512Z",
              "spark_jobs": null,
              "parent_msg_id": "3b0524e8-1612-4a24-811e-821b4ce5d1d5"
            },
            "text/plain": "StatementMeta(spark3p3sm, 44, 16, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "2023-07-05 15:59:28,476 - OEA - INFO - Number of new inbound rows processed: 78905\n"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "78905"
          },
          "execution_count": 33,
          "metadata": {}
        }
      ],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "publish(dfFactResourceActivity, 'stage2/Enriched/learning_analytics/v2.0/general/fact_resource_activity', 'stage3/Published/learning_analytics/v2.0/general/fact_resource_activity', primary_key='id')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "spark3p3sm",
              "session_id": "44",
              "statement_id": 17,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2023-07-05T16:00:04.1327409Z",
              "session_start_time": null,
              "execution_start_time": "2023-07-05T16:00:04.3203668Z",
              "execution_finish_time": "2023-07-05T16:00:22.1604746Z",
              "spark_jobs": null,
              "parent_msg_id": "8815c417-2a16-4bf6-be7f-89b6a2cd603a"
            },
            "text/plain": "StatementMeta(spark3p3sm, 44, 17, Finished, Available)"
          },
          "metadata": {}
        }
      ],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "oea.add_to_lake_db(f'stage3/Published/learning_analytics/v2.0/general/fact_resource_activity')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": null,
              "session_id": null,
              "statement_id": null,
              "state": "cancelled",
              "livy_statement_state": null,
              "queued_time": "2023-07-05T15:49:23.4033635Z",
              "session_start_time": null,
              "execution_start_time": null,
              "execution_finish_time": "2023-07-05T15:53:51.572476Z",
              "spark_jobs": null,
              "parent_msg_id": "6f2cd1e0-995f-4820-bf60-43c8a4cd86f8"
            },
            "text/plain": "StatementMeta(, , , Cancelled, )"
          },
          "metadata": {}
        }
      ],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "#oea.rm_if_exists('stage2/Enriched/learning_analytics')\r\n",
        "#oea.rm_if_exists('stage3/Published/learning_analytics')"
      ]
    }
  ],
  "metadata": {
    "description": null,
    "save_output": true,
    "kernelspec": {
      "name": "synapse_pyspark",
      "display_name": "Synapse PySpark"
    },
    "language_info": {
      "name": "python"
    },
    "synapse_widget": {
      "version": "0.1",
      "state": {}
    }
  }
}