{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "kernelspec": {
      "name": "synapse_pyspark",
      "display_name": "Synapse PySpark"
    },
    "language_info": {
      "name": "python"
    },
    "save_output": true,
    "synapse_widget": {
      "version": "0.1",
      "state": {}
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Hybrid Student Engagement Notebook\r\n",
        "\r\n",
        "This notebook creates 4 tables (student, dayactivity, yearactivity and calendar) into a new Spark database called s3_hybrid (stage 3 hybrid). \r\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "### Provision storage accounts\r\n",
        "\r\n",
        "The storage account variable has to be changed to the name of the storage account associated with your Azure resource group."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "spark2",
              "session_id": 17,
              "statement_id": 1,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2021-08-25T17:19:22.4676384Z",
              "session_start_time": "2021-08-25T17:19:22.5033561Z",
              "execution_start_time": "2021-08-25T17:21:26.7162535Z",
              "execution_finish_time": "2021-08-25T17:21:26.8718592Z"
            },
            "text/plain": "StatementMeta(spark2, 17, 1, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": []
        }
      ],
      "metadata": {},
      "source": [
        "from pyspark.sql.functions import *\r\n",
        "from pyspark.sql.window import Window\r\n",
        "\r\n",
        "# data lake and container information\r\n",
        "storage_account = 'stoeahybrid'\r\n",
        "use_test_env = True\r\n",
        "\r\n",
        "if use_test_env:\r\n",
        "    stage1 = 'abfss://test-env@' + storage_account + '.dfs.core.windows.net/stage1'\r\n",
        "    stage2 = 'abfss://test-env@' + storage_account + '.dfs.core.windows.net/stage2'\r\n",
        "    stage3 = 'abfss://test-env@' + storage_account + '.dfs.core.windows.net/stage3'\r\n",
        "else:\r\n",
        "    stage1 = 'abfss://stage1@' + storage_account + '.dfs.core.windows.net'\r\n",
        "    stage2 = 'abfss://stage2@' + storage_account + '.dfs.core.windows.net'\r\n",
        "    stage3 = 'abfss://stage3@' + storage_account + '.dfs.core.windows.net'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "### Load Raw Data from Lake\r\n",
        "To ensure that that the right tables are loaded, confirm that the file paths match your data lake storage containers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "spark2",
              "session_id": 17,
              "statement_id": 2,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2021-08-25T17:19:22.4693507Z",
              "session_start_time": null,
              "execution_start_time": "2021-08-25T17:21:26.974942Z",
              "execution_finish_time": "2021-08-25T17:21:45.8235208Z"
            },
            "text/plain": "StatementMeta(spark2, 17, 2, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": []
        }
      ],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "collapsed": true
      },
      "source": [
        "# load needed tables from parquet data lake storage\r\n",
        "dfStudAttendanceRaw = spark.read.format('parquet').load(f'{stage3}/contoso_sis/studentattendance')\r\n",
        "dfActivityV2Raw = spark.read.format('parquet').load(f'{stage3}/m365/Activity0p2')\r\n",
        "dfPersonRaw = spark.read.format('parquet').load(f'{stage3}/m365/Person')\r\n",
        "dfStudOrgRaw = spark.read.format('parquet').load(f'{stage3}/m365/StudentOrgAffiliation')\r\n",
        "dfOrgRaw = spark.read.format('parquet').load(f'{stage3}/m365/Org')\r\n",
        "dfSectionRaw = spark.read.format('parquet').load(f'{stage3}/m365/Section')\r\n",
        "dfCourseRaw = spark.read.format('parquet').load(f'{stage3}/m365/Course')\r\n",
        "dfRefRaw = spark.read.format('parquet').load(f'{stage3}/m365/RefDefinition')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## 1. Student table\r\n",
        "Contains students' information at a school level\r\n",
        "\r\n",
        "**Databases and tables used:**\r\n",
        "\r\n",
        "1. Spark DB: s3_m365 (stage 3 m365 feed)\r\n",
        "- Table: person (student PersonId and ExternalId relationship)\r\n",
        "- Table: org\r\n",
        "- Table: studentorgaffiliation\r\n",
        "- Table: section\r\n",
        "- Table: course\r\n",
        "- Table: refdefinition\r\n",
        "\r\n",
        "2. Spark DB: stage 3 SIS data\r\n",
        "- Table: studentattendance (student attendance by date, school, and course section)\r\n",
        "\r\n",
        "**Databases and tables created:**\r\n",
        "\r\n",
        "1. Spark DB: s3_hybrid (stage 3 hybrid)\r\n",
        "- Table: student"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Clean and Subset Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "spark2",
              "session_id": 17,
              "statement_id": 3,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2021-08-25T17:19:22.4709428Z",
              "session_start_time": null,
              "execution_start_time": "2021-08-25T17:21:45.914872Z",
              "execution_finish_time": "2021-08-25T17:21:46.9845418Z"
            },
            "text/plain": "StatementMeta(spark2, 17, 3, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": []
        }
      ],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "collapsed": true
      },
      "source": [
        "# take only active students\r\n",
        "dfPerson = dfPersonRaw.filter(dfPersonRaw.IsActive == 'True')\r\n",
        "dfStudOrg = dfStudOrgRaw.filter(dfStudOrgRaw.IsActive == 'True')\r\n",
        "\r\n",
        "# take needed columns and rename to align with other data sources\r\n",
        "dfPerson = dfPerson.select('Id','ExternalId')\r\n",
        "dfPerson = dfPerson.withColumnRenamed('Id', 'PersonId')\r\n",
        "\r\n",
        "dfStudOrg = dfStudOrg.select('PersonId', 'IsPrimary', 'IsActive', 'OrgId', 'RefGradeLevelId')\r\n",
        "\r\n",
        "dfOrg = dfOrgRaw.select('Identifier', 'name', 'Id')\r\n",
        "dfOrg = dfOrg.withColumnRenamed('Identifier', 'School_ID')\r\n",
        "dfOrg = dfOrg.withColumnRenamed('name', 'School_Name')\r\n",
        "dfOrg = dfOrg.withColumnRenamed('Id', 'OrgId')\r\n",
        "\r\n",
        "dfSection = dfSectionRaw.select('ExternalId', 'Name', 'CourseId', 'Id', 'Code', 'SessionId', 'OrgId')\r\n",
        "dfSection = dfSection.withColumnRenamed('ExternalId', 'section_id')\r\n",
        "dfSection = dfSection.withColumnRenamed('name', 'section_name')\r\n",
        "dfSection = dfSection.drop('School_Name')\r\n",
        "dfSection = dfSection.join(dfOrg, 'OrgId')\r\n",
        "\r\n",
        "dfCourse = dfCourseRaw.withColumnRenamed('Id', 'CourseId')\r\n",
        "dfCourse = dfCourse.withColumnRenamed('Name', 'Course')\r\n",
        "dfCourse = dfCourse.drop('ExternalId')\r\n",
        "\r\n",
        "dfRef = dfRefRaw.select('Id', 'Code', 'Description')\r\n",
        "dfRef = dfRef.withColumnRenamed('Id', 'RefId')\r\n",
        "\r\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "spark2",
              "session_id": 17,
              "statement_id": 4,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2021-08-25T17:19:22.472901Z",
              "session_start_time": null,
              "execution_start_time": "2021-08-25T17:21:47.0761688Z",
              "execution_finish_time": "2021-08-25T17:21:51.0327168Z"
            },
            "text/plain": "StatementMeta(spark2, 17, 4, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-RECORD 0---------------------------------\n School_ID         | sch1                 \n ExternalId        | 68f1c007e6178d345... \n Period            | 1                    \n section_id        | sec1                 \n PresenceFlag      | 1                    \n attendance_status | Present              \n Date              | 2021-02-10           \n School_Name       | Gallagher High       \n OrgId             | edp_sch1             \nonly showing top 1 row"
          ]
        }
      ],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "collapsed": true
      },
      "source": [
        "# combine student information and school details with attendance data\r\n",
        "dfStudAttendance = dfStudAttendanceRaw.select('student_id', 'school_id', 'attendance_date', 'Period', 'section_id', \r\n",
        "                        'PresenceFlag', 'attendance_status')\r\n",
        "                  \r\n",
        "dfStudAttendance = dfStudAttendance.withColumnRenamed('school_id', 'School_ID')\r\n",
        "dfStudAttendance = dfStudAttendance.withColumnRenamed('student_id','ExternalId')\r\n",
        "dfStudAttendance = dfStudAttendance.withColumn(\"Date\", to_date(col(\"attendance_date\"), 'yyyy-MM-dd'))\r\n",
        "dfStudAttendance = dfStudAttendance.drop('attendance_date')\r\n",
        "\r\n",
        "dfStudAttendance = dfStudAttendance.join(dfOrg, 'School_ID')\r\n",
        "dfStudAttendance.show(1,vertical=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "### Find Primary School\r\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "spark2",
              "session_id": 17,
              "statement_id": 5,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2021-08-25T17:19:22.4747057Z",
              "session_start_time": null,
              "execution_start_time": "2021-08-25T17:21:51.1251053Z",
              "execution_finish_time": "2021-08-25T17:21:56.4199733Z"
            },
            "text/plain": "StatementMeta(spark2, 17, 5, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-RECORD 0---------------------------\n ExternalId  | 3b7e980ef9b5d89af... \n School_ID   | sch5                 \n School_Name | Robinson High        \n-RECORD 1---------------------------\n ExternalId  | 418cf724bc5222168... \n School_ID   | sch5                 \n School_Name | Robinson High        \n-RECORD 2---------------------------\n ExternalId  | 8591cfe8502d9b9f6... \n School_ID   | sch4                 \n School_Name | Mitchell High        \nonly showing top 3 rows"
          ]
        }
      ],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "collapsed": true
      },
      "source": [
        "# find school which students have highest attendance count\r\n",
        "df = (dfStudAttendance.groupBy(\"ExternalId\", 'School_ID', 'School_Name')\r\n",
        "    .agg(sum(\"PresenceFlag\").alias(\"Present_Count\")))\r\n",
        "\r\n",
        "\r\n",
        "w = Window.partitionBy('ExternalId')\r\n",
        "dfStudSchoolPrimary = df.withColumn('maxPres', max('Present_Count').over(w))\\\r\n",
        "    .where(col('Present_Count') == col('maxPres'))\\\r\n",
        "    .drop('maxPres').drop('Present_Count')\r\n",
        "\r\n",
        "dfStudSchoolPrimary.show(3, vertical=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "spark2",
              "session_id": 17,
              "statement_id": 6,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2021-08-25T17:19:22.4777995Z",
              "session_start_time": null,
              "execution_start_time": "2021-08-25T17:21:56.516487Z",
              "execution_finish_time": "2021-08-25T17:21:56.6773626Z"
            },
            "text/plain": "StatementMeta(spark2, 17, 6, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": []
        }
      ],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "collapsed": true
      },
      "source": [
        "# rename columns to indicate primary school\r\n",
        "dfStudSchoolPrimary = dfStudSchoolPrimary.withColumnRenamed('School_Name', 'SchoolNamePrimary')\r\n",
        "dfStudSchoolPrimary = dfStudSchoolPrimary.withColumnRenamed('School_ID', 'SchoolIdPrimary')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Combine tables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "spark2",
              "session_id": 17,
              "statement_id": 7,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2021-08-25T17:19:22.4798517Z",
              "session_start_time": null,
              "execution_start_time": "2021-08-25T17:21:56.7659338Z",
              "execution_finish_time": "2021-08-25T17:22:03.7239336Z"
            },
            "text/plain": "StatementMeta(spark2, 17, 7, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-RECORD 0---------------------------------\n ExternalId        | 68f1c007e6178d345... \n PersonId          | f2447993213182b11... \n IsActive          | true                 \n SchoolNamePrimary | Gallagher High       \n SchoolIdPrimary   | sch1                 \n GradeName         | Eleventh grade       \nonly showing top 1 row\n\n100"
          ]
        }
      ],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "collapsed": true
      },
      "source": [
        "# join person table to student and ref tables to create student profile \r\n",
        "dfStudent = dfPerson.join(dfStudOrg, 'PersonId')\r\n",
        "dfStudent = dfStudent.withColumnRenamed('RefGradeLevelId', 'RefId')\r\n",
        "dfStudent = dfStudent.join(dfRef, 'RefId')\r\n",
        "dfStudentFinal = dfStudent.join(dfStudSchoolPrimary, 'ExternalId')\r\n",
        "dfStudentFinal = dfStudentFinal.withColumnRenamed('Code', 'GradeLevel')\r\n",
        "dfStudentFinal = dfStudentFinal.withColumnRenamed('Description', 'GradeName')\r\n",
        "dfStudentFinal = dfStudentFinal.select('ExternalId',  'PersonId', 'IsActive', 'SchoolNamePrimary', 'SchoolIdPrimary', 'OrgId', 'GradeLevel', 'GradeName')\r\n",
        "dfStudentFinal = dfStudentFinal.drop('OrgId', 'GradeLevel')\r\n",
        "dfStudentFinal.show(1, vertical=True)\r\n",
        "print(dfStudentFinal.count())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "### Write Data Back to Lake"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "spark2",
              "session_id": 17,
              "statement_id": 8,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2021-08-25T17:19:23.8335543Z",
              "session_start_time": null,
              "execution_start_time": "2021-08-25T17:22:03.8189375Z",
              "execution_finish_time": "2021-08-25T17:22:07.5997191Z"
            },
            "text/plain": "StatementMeta(spark2, 17, 8, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": []
        }
      ],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "collapsed": true
      },
      "source": [
        "# write back to the lake\r\n",
        "dfStudentFinal.write.format('parquet').mode('overwrite').save(stage3 + '/test_s3_hybrid/Student')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "### Load to Spark DB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "spark2",
              "session_id": 17,
              "statement_id": 9,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2021-08-25T17:19:26.7407518Z",
              "session_start_time": null,
              "execution_start_time": "2021-08-25T17:22:07.6937252Z",
              "execution_finish_time": "2021-08-25T17:22:20.3597791Z"
            },
            "text/plain": "StatementMeta(spark2, 17, 9, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": []
        }
      ],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "collapsed": true
      },
      "source": [
        "# Create spark db to allow for access to the data in the delta-lake via SQL on-demand.\r\n",
        "# This is only creating metadata for SQL on-demand, pointing to the data in the delta-lake.\r\n",
        "# This also makes it possible to connect in Power BI via the azure sql data source connector.\r\n",
        "def create_spark_db(db_name, source_path):\r\n",
        "    spark.sql(f'CREATE DATABASE IF NOT EXISTS {db_name}')\r\n",
        "    spark.sql(f\"DROP TABLE IF EXISTS {db_name}.Student\")\r\n",
        "    spark.sql(f\"create table if not exists {db_name}.Student using PARQUET location '{source_path}/Student'\")\r\n",
        "    \r\n",
        "create_spark_db('test_s3_hybrid', stage3 + '/test_s3_hybrid')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## 2. Calendar table\r\n",
        "Contains a basic calendar table to support data analysis in a Power BI dashboard.\r\n",
        "\r\n",
        "**Databases and tables used:**\r\n",
        "- None\r\n",
        "\r\n",
        "**Databases and tables created:**\r\n",
        "\r\n",
        "1. Spark DB: s3_hybrid (stage 3 hybrid)\r\n",
        "- Table: calendar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "spark2",
              "session_id": 17,
              "statement_id": 10,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2021-08-25T17:19:27.7266179Z",
              "session_start_time": null,
              "execution_start_time": "2021-08-25T17:22:20.4512615Z",
              "execution_finish_time": "2021-08-25T17:22:29.0878884Z"
            },
            "text/plain": "StatementMeta(spark2, 17, 10, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+----+-------+--------+----+---+\n|      Date|Year|  Month|MonthNum|Week|Day|\n+----------+----+-------+--------+----+---+\n|2020-01-01|2020|January|       1|   1|  1|\n|2020-01-02|2020|January|       1|   1|  2|\n+----------+----+-------+--------+----+---+\nonly showing top 2 rows"
          ]
        }
      ],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "collapsed": true
      },
      "source": [
        "# date range\r\n",
        "start = \"2020-01-01\"\r\n",
        "stop = \"2021-12-30\"\r\n",
        "\r\n",
        "# create calendar dataframe\r\n",
        "temp_df = spark.createDataFrame([(start, stop)], (\"start\", \"stop\"))\r\n",
        "temp_df = temp_df.select([col(c).cast(\"timestamp\") for c in (\"start\", \"stop\")])\r\n",
        "temp_df = temp_df.withColumn(\"stop\",date_add(\"stop\",1).cast(\"timestamp\"))\r\n",
        "temp_df = temp_df.select([col(c).cast(\"long\") for c in (\"start\", \"stop\")])\r\n",
        "start, stop = temp_df.first()\r\n",
        "interval=60*60*24\r\n",
        "\r\n",
        "df = spark.range(start,stop,interval).select(col(\"id\").cast(\"timestamp\").alias(\"DateTime\"))\r\n",
        "df = df.withColumn(\"Date\", to_date(col(\"DateTime\")))\r\n",
        "\r\n",
        "df = df.drop(\"DateTime\")\r\n",
        "df = df.withColumn('Year', date_format('Date', 'YYYY'))\r\n",
        "df = df.withColumn('Month', date_format('Date', 'MMMM'))\r\n",
        "df = df.withColumn('MonthNum', date_format('Date', 'M'))\r\n",
        "df = df.withColumn('Week', date_format('Date', 'W'))\r\n",
        "df = df.withColumn('Day', date_format('Date', 'D'))\r\n",
        "df.show(2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Write Data Back to Lake"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "spark2",
              "session_id": 17,
              "statement_id": 11,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2021-08-25T17:19:31.2210474Z",
              "session_start_time": null,
              "execution_start_time": "2021-08-25T17:22:29.1838868Z",
              "execution_finish_time": "2021-08-25T17:22:30.993935Z"
            },
            "text/plain": "StatementMeta(spark2, 17, 11, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": []
        }
      ],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "collapsed": true
      },
      "source": [
        "# write back to the lake in stage 3 ds3_main directory\r\n",
        "df.write.format('parquet').mode('overwrite').save(stage3 + '/test_s3_hybrid/Calendar')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "### Load to Spark DB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "spark2",
              "session_id": 17,
              "statement_id": 12,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2021-08-25T17:20:07.7102696Z",
              "session_start_time": null,
              "execution_start_time": "2021-08-25T17:22:31.079749Z",
              "execution_finish_time": "2021-08-25T17:22:33.8510989Z"
            },
            "text/plain": "StatementMeta(spark2, 17, 12, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": []
        }
      ],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "collapsed": true
      },
      "source": [
        "# Create spark db to allow for access to the data in the data lake via SQL on-demand.\r\n",
        "#This is only creating metadata for SQL on-demand, pointing to the data in the delta-lake.\r\n",
        "# This also makes it possible to connect in Power BI via the azure sql data source connector.\r\n",
        "def create_spark_db(db_name, source_path):\r\n",
        "    spark.sql(f'CREATE DATABASE IF NOT EXISTS {db_name}')\r\n",
        "    spark.sql(f\"DROP TABLE IF EXISTS {db_name}.Calendar\")\r\n",
        "    spark.sql(f\"create table if not exists {db_name}.Calendar using PARQUET location '{source_path}/Calendar'\")\r\n",
        "\r\n",
        "create_spark_db('test_s3_hybrid', stage3 + '/test_s3_hybrid')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## 3. Dayactivity table\r\n",
        "Contains student daily digital and in-person activity \r\n",
        "\r\n",
        "**Databases and tables used:** \r\n",
        "\r\n",
        "1. Spark DB: s3_m365 (stage 3 m365 feed)\r\n",
        "- Table: Activity0p2 (user m365 app activity v2)\r\n",
        "\r\n",
        "2. Spark DB: stage 3 SIS data\r\n",
        "- Table: studentattendance (student attendance by date, school, and course section)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "### Clean and Subset data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "spark2",
              "session_id": 17,
              "statement_id": 13,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2021-08-25T17:23:05.1499331Z",
              "session_start_time": null,
              "execution_start_time": "2021-08-25T17:23:05.2448777Z",
              "execution_finish_time": "2021-08-25T17:23:12.1007718Z"
            },
            "text/plain": "StatementMeta(spark2, 17, 13, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-RECORD 0---------------------------------\n PersonId          | f2447993213182b11... \n ExternalId        | 68f1c007e6178d345... \n Date              | 2021-02-21           \n attendance_status | Present              \n PresenceFlag      | 1                    \n Period            | 1                    \n SchoolNamePrimary | Gallagher High       \n SessionId         | edp_term2            \n SectionId         | sec15                \n CourseId          | edp_course5          \n Course            | Science Biology      \nonly showing top 1 row\n\n1050"
          ]
        }
      ],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "collapsed": true
      },
      "source": [
        "# combine student attendance with section and course data\r\n",
        "dfStudAttendanceFinal = dfStudAttendance.join(dfStudentFinal, 'ExternalId')\r\n",
        "dfStudAttendanceFinal = dfStudAttendanceFinal.join(dfSection, ['section_id', 'School_ID'])\r\n",
        "dfStudAttendanceFinal = dfStudAttendanceFinal.join(dfCourse, 'CourseId')\r\n",
        "dfStudAttendanceFinal = dfStudAttendanceFinal.select('PersonId', 'ExternalId', 'Date', 'attendance_status', 'PresenceFlag'\r\n",
        "                                                    ,'Period', 'SchoolNamePrimary', 'SessionId', 'section_id', 'CourseId', 'Course')\r\n",
        "dfStudAttendanceFinal = dfStudAttendanceFinal.withColumnRenamed('section_id', 'SectionId')\r\n",
        "dfStudAttendanceFinal.show(1, vertical=True)\r\n",
        "print(dfStudAttendanceFinal.count())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "spark2",
              "session_id": 17,
              "statement_id": 14,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2021-08-25T17:23:17.617749Z",
              "session_start_time": null,
              "execution_start_time": "2021-08-25T17:23:17.7325851Z",
              "execution_finish_time": "2021-08-25T17:23:21.7963777Z"
            },
            "text/plain": "StatementMeta(spark2, 17, 14, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "56"
          ]
        }
      ],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "collapsed": true
      },
      "source": [
        "# isolate in-person school days\r\n",
        "schoolDays = dfStudAttendanceFinal.select('Date').distinct()\r\n",
        "print(schoolDays.count())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "spark2",
              "session_id": 17,
              "statement_id": 15,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2021-08-25T17:23:19.1052907Z",
              "session_start_time": null,
              "execution_start_time": "2021-08-25T17:23:21.9025319Z",
              "execution_finish_time": "2021-08-25T17:23:27.2034345Z"
            },
            "text/plain": "StatementMeta(spark2, 17, 15, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-RECORD 0---------------------------------\n PersonId          | f2447993213182b11... \n AppName           | Excel                \n SignalType        | FileModified         \n StartTime         | 2021-03-05 15:46:46  \n MeetingDuration   | 00:11:04             \n ExternalId        | 68f1c007e6178d345... \n IsActive          | true                 \n SchoolNamePrimary | Gallagher High       \n SchoolIdPrimary   | sch1                 \n GradeName         | Eleventh grade       \nonly showing top 1 row\n\n23180"
          ]
        }
      ],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "collapsed": true
      },
      "source": [
        "# take only needed columns and filter for only students\r\n",
        "dfActivityV2 = dfActivityV2Raw.where(col('ActorRole') == 'Student').select('PersonId','AppName', 'SignalType'\r\n",
        "                                    ,'StartTime', 'MeetingDuration')\r\n",
        "\r\n",
        "# active students only, include external id\r\n",
        "dfActivityV2 = dfActivityV2.join(dfStudentFinal, 'PersonId')\r\n",
        "dfActivityV2.show(1, vertical=True)\r\n",
        "print(dfActivityV2.count())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Aggregate Activity by Date\r\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "spark2",
              "session_id": 17,
              "statement_id": 16,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2021-08-25T17:23:22.8179167Z",
              "session_start_time": null,
              "execution_start_time": "2021-08-25T17:23:27.2893497Z",
              "execution_finish_time": "2021-08-25T17:23:30.1508254Z"
            },
            "text/plain": "StatementMeta(spark2, 17, 16, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-RECORD 0---------------------------\n PersonId    | 201f952a2007e9aa4... \n ExternalId  | ee4f65129e61c4d97... \n AppName     | PDF viewers          \n SignalType  | AddedToSharedWithMe  \n Date        | 2021-02-19           \n DurationSum | 20                   \nonly showing top 1 row"
          ]
        }
      ],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "collapsed": true
      },
      "source": [
        "# convert MeetingDuration column to time format\r\n",
        "dfActivityV2 = dfActivityV2.withColumn('MeetingDuration', to_timestamp('MeetingDuration'))\r\n",
        "dfActivityV2 = dfActivityV2.withColumn('HourToMinutes', hour(col('MeetingDuration'))*60)\r\n",
        "dfActivityV2 = dfActivityV2.withColumn('Minutes', minute(col('MeetingDuration')))\r\n",
        "dfActivityV2 = dfActivityV2.withColumn('Duration', col('HourToMinutes') + col('Minutes'))\r\n",
        "\r\n",
        "# aggregation of activity\r\n",
        "dfActivityV2agg = (dfActivityV2.groupBy(\"PersonId\", \"ExternalId\",\r\n",
        "                    \"AppName\", \"SignalType\",\r\n",
        "                    to_date(\"StartTime\").alias(\"Date\"))\r\n",
        "    .agg(sum(\"Duration\").alias(\"DurationSum\")))\r\n",
        "\r\n",
        "dfActivityV2agg.show(1,vertical=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "spark2",
              "session_id": 17,
              "statement_id": 17,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2021-08-25T17:23:24.3174633Z",
              "session_start_time": null,
              "execution_start_time": "2021-08-25T17:23:30.242556Z",
              "execution_finish_time": "2021-08-25T17:23:35.632726Z"
            },
            "text/plain": "StatementMeta(spark2, 17, 17, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1050\n-RECORD 0----------------------------\n PersonId     | 70395011b16faae0c... \n ExternalId   | 62673a604d240d8ca... \n Date         | 2021-02-26           \n SectionId    | sec5                 \n Course       | Art                  \n Present_Mean | 1.0                  \n Present      | 1                    \nonly showing top 1 row"
          ]
        }
      ],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "collapsed": true
      },
      "source": [
        "# count number of presence flags per date\r\n",
        "dfStudAttendanceAgg = (dfStudAttendanceFinal.groupBy('PersonId', 'ExternalId', 'Date', 'SectionId', 'Course')\r\n",
        "                    .agg(mean(\"PresenceFlag\").alias(\"Present_Mean\")))\r\n",
        "\r\n",
        "dfStudAttendanceAgg = dfStudAttendanceAgg.withColumn('Present', when(col('Present_Mean') > 0, 1).otherwise(0))\r\n",
        "\r\n",
        "print(dfStudAttendanceAgg.count())\r\n",
        "dfStudAttendanceAgg.show(1,vertical=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Daily activity: Merge into a single wide table\r\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "spark2",
              "session_id": 17,
              "statement_id": 18,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2021-08-25T17:23:25.2343195Z",
              "session_start_time": null,
              "execution_start_time": "2021-08-25T17:23:35.733861Z",
              "execution_finish_time": "2021-08-25T17:24:02.8711143Z"
            },
            "text/plain": "StatementMeta(spark2, 17, 18, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-RECORD 0-------------------------------------\n PersonId              | 0b039b8211f7c0bcf... \n ExternalId            | 87856b6419d0ec873... \n Date                  | 2021-03-05           \n TeamsMeetingsDuration | null                 \n Assignments           | 0                    \n TeamsCommunications   | 0                    \n-RECORD 1-------------------------------------\n PersonId              | 0b039b8211f7c0bcf... \n ExternalId            | 87856b6419d0ec873... \n Date                  | 2021-03-05           \n TeamsMeetingsDuration | null                 \n Assignments           | 0                    \n TeamsCommunications   | 0                    \n-RECORD 2-------------------------------------\n PersonId              | 0b039b8211f7c0bcf... \n ExternalId            | 87856b6419d0ec873... \n Date                  | 2021-03-05           \n TeamsMeetingsDuration | null                 \n Assignments           | 0                    \n TeamsCommunications   | 0                    \n-RECORD 3-------------------------------------\n PersonId              | 0b039b8211f7c0bcf... \n ExternalId            | 87856b6419d0ec873... \n Date                  | 2021-03-05           \n TeamsMeetingsDuration | null                 \n Assignments           | 0                    \n TeamsCommunications   | 0                    \n-RECORD 4-------------------------------------\n PersonId              | 0b039b8211f7c0bcf... \n ExternalId            | 87856b6419d0ec873... \n Date                  | 2021-03-05           \n TeamsMeetingsDuration | null                 \n Assignments           | 0                    \n TeamsCommunications   | 0                    \nonly showing top 5 rows\n\n-RECORD 0-------------------------------------\n PersonId              | 0b039b8211f7c0bcf... \n ExternalId            | 87856b6419d0ec873... \n Date                  | 2021-03-05           \n TeamsMeetingsDuration | null                 \n Assignments           | 0.0                  \n TeamsCommunications   | 0.15384615384615385  \n-RECORD 1-------------------------------------\n PersonId              | 0f53869a3bedf6b2c... \n ExternalId            | 2b946c8bd9fdcb8b2... \n Date                  | 2021-04-01           \n TeamsMeetingsDuration | null                 \n Assignments           | 0.0                  \n TeamsCommunications   | 0.0                  \n-RECORD 2-------------------------------------\n PersonId              | 1b138f85c5e28273d... \n ExternalId            | 5b26542cb1e95a519... \n Date                  | 2021-02-12           \n TeamsMeetingsDuration | null                 \n Assignments           | 0.0                  \n TeamsCommunications   | 0.2                  \n-RECORD 3-------------------------------------\n PersonId              | 23faa0c931e62c1e4... \n ExternalId            | 77c6fef0d5669d70c... \n Date                  | 2021-03-31           \n TeamsMeetingsDuration | null                 \n Assignments           | 0.0                  \n TeamsCommunications   | 0.14285714285714285  \n-RECORD 4-------------------------------------\n PersonId              | 270841e2bc7b04f2d... \n ExternalId            | 40abef6a470cac55a... \n Date                  | 2021-04-03           \n TeamsMeetingsDuration | null                 \n Assignments           | 0.0                  \n TeamsCommunications   | 0.0                  \nonly showing top 5 rows\n\n5199"
          ]
        }
      ],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "collapsed": true
      },
      "source": [
        "# focus on teams meetings, assignments, and communications\r\n",
        "\r\n",
        "df1 = dfActivityV2agg.where( ( col(\"AppName\") == \"Teams\" ) &\r\n",
        "                            ( col(\"SignalType\") == \"CallRecordSummarized\" ))\r\n",
        "\r\n",
        "dfDayAct = df1.select(\"PersonId\", \"ExternalId\", \"Date\", \"DurationSum\")\r\n",
        "dfDayAct = dfDayAct.withColumnRenamed(\"DurationSum\", \"TeamsMeetingsDuration\")\r\n",
        "\r\n",
        "df2 = dfActivityV2agg.withColumn('Assignments', when(( col(\"AppName\") == \"Assignments\" ) & \r\n",
        "                            ( col(\"SignalType\") == \"SubmissionEvent\" ) , 1).otherwise(0))\r\n",
        "df2 = df2.select(\"PersonId\", \"ExternalId\", \"Date\", \"Assignments\")\r\n",
        "\r\n",
        "dfDayAct = dfDayAct.join(df2, [\"PersonId\", \"ExternalId\", \"Date\"], 'outer')\r\n",
        "\r\n",
        "df3 = dfActivityV2agg.withColumn('TeamsCommunications', when(( col(\"AppName\") == \"Teams\" ) & \r\n",
        "                        ( col(\"SignalType\").isin(['AddedToSharedWithMe', 'CommentCreated',\r\n",
        "                            'CommentDeleted', 'ExpandChannelMessage', 'PostChannelMessage',\r\n",
        "                            'ReactedWithEmoji', 'ReplyChannelMessage', 'Unlike',\r\n",
        "                            'UserAtMentioned', 'VisitTeamChannel'])), 1).otherwise(0))\r\n",
        "df3 = df3.select(\"PersonId\", \"ExternalId\", \"Date\", \"TeamsCommunications\")\r\n",
        "\r\n",
        "dfDayAct = dfDayAct.join(df3, [\"PersonId\", \"ExternalId\", \"Date\"], 'outer')\r\n",
        "\r\n",
        "\r\n",
        "dfDayAct.show(5, vertical=True)\r\n",
        "\r\n",
        "dfDayAct = dfDayAct.groupBy(\"PersonId\", \"ExternalId\", \"Date\").agg(sum('TeamsMeetingsDuration').alias('TeamsMeetingsDuration'), mean('Assignments').alias('Assignments'), mean('TeamsCommunications').alias('TeamsCommunications'))\r\n",
        " \r\n",
        "dfDayAct.show(5, vertical=True)\r\n",
        "print(dfDayAct.count())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "spark2",
              "session_id": 17,
              "statement_id": 19,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2021-08-25T17:23:25.897224Z",
              "session_start_time": null,
              "execution_start_time": "2021-08-25T17:24:02.9604013Z",
              "execution_finish_time": "2021-08-25T17:24:19.7872259Z"
            },
            "text/plain": "StatementMeta(spark2, 17, 19, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-RECORD 0-------------------------------------\n PersonId              | 0b039b8211f7c0bcf... \n ExternalId            | 87856b6419d0ec873... \n Date                  | 2021-03-05           \n TeamsMeetingsDuration | null                 \n Assignments           | 0.0                  \n TeamsCommunications   | 0.15384615384615385  \n SectionId             | null                 \n Course                | null                 \n Present_Mean          | null                 \n Present               | null                 \n-RECORD 1-------------------------------------\n PersonId              | 0f53869a3bedf6b2c... \n ExternalId            | 2b946c8bd9fdcb8b2... \n Date                  | 2021-04-01           \n TeamsMeetingsDuration | null                 \n Assignments           | 0.0                  \n TeamsCommunications   | 0.0                  \n SectionId             | null                 \n Course                | null                 \n Present_Mean          | null                 \n Present               | null                 \nonly showing top 2 rows\n\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "5812"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {},
          "execution_count": 19,
          "metadata": {}
        }
      ],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "collapsed": true
      },
      "source": [
        "# add in person attendance\r\n",
        "dfDayAct = dfDayAct.join(dfStudAttendanceAgg, [\"PersonId\", \"ExternalId\", \"Date\"], 'outer')\r\n",
        "\r\n",
        "dfDayAct.show(2,vertical=True)\r\n",
        "dfDayAct.count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "spark2",
              "session_id": 17,
              "statement_id": 20,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2021-08-25T17:23:26.7738571Z",
              "session_start_time": null,
              "execution_start_time": "2021-08-25T17:24:19.8854915Z",
              "execution_finish_time": "2021-08-25T17:24:38.7856694Z"
            },
            "text/plain": "StatementMeta(spark2, 17, 20, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4186\n55"
          ]
        }
      ],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "collapsed": true
      },
      "source": [
        "# subset dates to only school dates\r\n",
        "dfDayAct = dfDayAct.join(schoolDays, [\"Date\"], \"inner\")\r\n",
        "\r\n",
        "print(dfDayAct.count())\r\n",
        "\r\n",
        "schoolDaysCheck = dfDayAct.select('Date').distinct()\r\n",
        "\r\n",
        "print(schoolDaysCheck.count())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "spark2",
              "session_id": 17,
              "statement_id": 21,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2021-08-25T17:23:28.8040263Z",
              "session_start_time": null,
              "execution_start_time": "2021-08-25T17:24:38.8785229Z",
              "execution_finish_time": "2021-08-25T17:24:39.0385499Z"
            },
            "text/plain": "StatementMeta(spark2, 17, 21, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('Date', 'date'), ('PersonId', 'string'), ('ExternalId', 'string'), ('TeamsMeetingsDuration', 'bigint'), ('Assignments', 'double'), ('TeamsCommunications', 'double'), ('SectionId', 'string'), ('Course', 'string'), ('Present_Mean', 'double'), ('Present', 'int')]"
          ]
        }
      ],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "collapsed": true
      },
      "source": [
        "print(dfDayAct.dtypes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "spark2",
              "session_id": 17,
              "statement_id": 22,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2021-08-25T17:23:29.716162Z",
              "session_start_time": null,
              "execution_start_time": "2021-08-25T17:24:39.1318857Z",
              "execution_finish_time": "2021-08-25T17:25:01.1505199Z"
            },
            "text/plain": "StatementMeta(spark2, 17, 22, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4186\n-RECORD 0-------------------------------------\n Date                  | 2021-04-29           \n PersonId              | e2a7969d1392cd0bf... \n ExternalId            | 9baf0a604c20c7f34... \n TeamsMeetingsDuration | 0                    \n Assignments           | 0.0                  \n TeamsCommunications   | 0.0                  \n SectionId             | sec88                \n Course                | Math - Algebra       \n Present_Mean          | 1.0                  \n Present               | 1                    \nonly showing top 1 row"
          ]
        }
      ],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "collapsed": true
      },
      "source": [
        "# fill missing with 0\r\n",
        "dfDayAct = dfDayAct.na.fill(0)\r\n",
        "\r\n",
        "print(dfDayAct.count())\r\n",
        "dfDayAct.show(1, vertical=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "spark2",
              "session_id": 17,
              "statement_id": 23,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2021-08-25T17:23:30.9499038Z",
              "session_start_time": null,
              "execution_start_time": "2021-08-25T17:25:01.2528448Z",
              "execution_finish_time": "2021-08-25T17:25:11.9182224Z"
            },
            "text/plain": "StatementMeta(spark2, 17, 23, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-RECORD 0-----------------------------------------\n Date                      | 2021-04-29           \n PersonId                  | 7c654ccc81f1ba474... \n ExternalId                | aa5bd029c7fd4ec6d... \n TeamsMeetingsDuration     | 0                    \n Assignments               | 0.0                  \n TeamsCommunications       | 0.0                  \n SectionId                 | sec75                \n Course                    | English Language     \n Present_Mean              | 1.0                  \n Present                   | 1                    \n ActiveTeamsMeetings       | 0                    \n ActiveTeamsCommunications | 0                    \n ActiveAssignments         | 0                    \n DigitallyActive           | 0                    \nonly showing top 1 row"
          ]
        }
      ],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "collapsed": true
      },
      "source": [
        "# add activity indicator columns\r\n",
        "dfDayAct= dfDayAct.withColumn('ActiveTeamsMeetings', when(col('TeamsMeetingsDuration') > 0, 1).otherwise(0))\r\n",
        "dfDayAct= dfDayAct.withColumn('ActiveTeamsCommunications', when(col('TeamsCommunications') > 0 , 1).otherwise(0))\r\n",
        "dfDayAct= dfDayAct.withColumn('ActiveAssignments', when(col('Assignments') > 0 , 1).otherwise(0))\r\n",
        "dfDayAct= dfDayAct.withColumn('DigitallyActive', when( \\\r\n",
        "                (col('ActiveTeamsMeetings')+ col('ActiveTeamsCommunications')+ col('ActiveAssignments'))\\\r\n",
        "                 > 0, 1).otherwise(0))\r\n",
        "\r\n",
        "dfDayAct.show(1,vertical=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## 3. Dayactivity table\r\n",
        "Contains student daily digital and in-person activity \r\n",
        "\r\n",
        "**Databases and tables used:** \r\n",
        "\r\n",
        "1. Spark DB: s3_m365 (stage 3 m365 feed)\r\n",
        "- Table: Activity0p2 (user m365 app activity v2)\r\n",
        "\r\n",
        "2. Spark DB: stage 3 SIS data\r\n",
        "- Table: studentattendance (student attendance by date, school, and course section)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Yearly Aggregates\r\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "spark2",
              "session_id": 17,
              "statement_id": 24,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2021-08-25T17:23:32.0582151Z",
              "session_start_time": null,
              "execution_start_time": "2021-08-25T17:25:12.0119552Z",
              "execution_finish_time": "2021-08-25T17:25:37.2374159Z"
            },
            "text/plain": "StatementMeta(spark2, 17, 24, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100\n-RECORD 0---------------------------------------------\n PersonId                      | b52042e19537f0557... \n ExternalId                    | 8228c26c3604bac68... \n DaysActiveTeamsMeetings       | 0                    \n DaysActiveTeamsCommunications | 4                    \n DaysActiveAssignments         | 0                    \n DaysDigitallyActive           | 4                    \n DaysPresent                   | 12                   \n Present_Perc                  | 0.21428571428571427  \n Atten_Threshold_Met           | 0                    \n-RECORD 1---------------------------------------------\n PersonId                      | 0f3f3f677ce0424a2... \n ExternalId                    | b2437b12e9221fae3... \n DaysActiveTeamsMeetings       | 0                    \n DaysActiveTeamsCommunications | 0                    \n DaysActiveAssignments         | 0                    \n DaysDigitallyActive           | 0                    \n DaysPresent                   | 12                   \n Present_Perc                  | 0.21428571428571427  \n Atten_Threshold_Met           | 0                    \n-RECORD 2---------------------------------------------\n PersonId                      | 7b507d8c7ee233091... \n ExternalId                    | 3b7e980ef9b5d89af... \n DaysActiveTeamsMeetings       | 4                    \n DaysActiveTeamsCommunications | 21                   \n DaysActiveAssignments         | 0                    \n DaysDigitallyActive           | 21                   \n DaysPresent                   | 12                   \n Present_Perc                  | 0.21428571428571427  \n Atten_Threshold_Met           | 0                    \n-RECORD 3---------------------------------------------\n PersonId                      | 88ed6363f9e790a10... \n ExternalId                    | 766e4d97efd7558bd... \n DaysActiveTeamsMeetings       | 0                    \n DaysActiveTeamsCommunications | 7                    \n DaysActiveAssignments         | 0                    \n DaysDigitallyActive           | 7                    \n DaysPresent                   | 12                   \n Present_Perc                  | 0.21428571428571427  \n Atten_Threshold_Met           | 0                    \n-RECORD 4---------------------------------------------\n PersonId                      | 58afd08fde1bd0ab6... \n ExternalId                    | 4e3cfaa9596ede59c... \n DaysActiveTeamsMeetings       | 2                    \n DaysActiveTeamsCommunications | 4                    \n DaysActiveAssignments         | 0                    \n DaysDigitallyActive           | 6                    \n DaysPresent                   | 12                   \n Present_Perc                  | 0.21428571428571427  \n Atten_Threshold_Met           | 0                    \nonly showing top 5 rows"
          ]
        }
      ],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "collapsed": true
      },
      "source": [
        "dfYearAct = dfDayAct.groupBy(\"PersonId\", \"ExternalId\")\\\r\n",
        "    .agg(sum(\"ActiveTeamsMeetings\").alias(\"DaysActiveTeamsMeetings\")\\\r\n",
        "    ,sum(\"ActiveTeamsCommunications\").alias(\"DaysActiveTeamsCommunications\")\\\r\n",
        "    ,sum(\"ActiveAssignments\").alias(\"DaysActiveAssignments\")\\\r\n",
        "    ,sum(\"DigitallyActive\").alias(\"DaysDigitallyActive\")\\\r\n",
        "    ,sum(\"Present\").alias(\"DaysPresent\"))\r\n",
        "\r\n",
        "\r\n",
        "dfYearAct = dfYearAct.withColumn('Present_Perc', \r\n",
        "            col(\"DaysPresent\")/schoolDays.count())\r\n",
        "\r\n",
        "dfYearAct = dfYearAct.withColumn('Atten_Threshold_Met', \r\n",
        "            when(col('Present_Perc') > 0.9, 1).otherwise(0))\r\n",
        "\r\n",
        "print(dfYearAct.count())\r\n",
        "dfYearAct.show(5,vertical=True)\r\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Write Back to the Lake"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "spark2",
              "session_id": 17,
              "statement_id": 25,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2021-08-25T17:24:29.179669Z",
              "session_start_time": null,
              "execution_start_time": "2021-08-25T17:25:37.3771564Z",
              "execution_finish_time": "2021-08-25T17:26:04.097179Z"
            },
            "text/plain": "StatementMeta(spark2, 17, 25, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": []
        }
      ],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "collapsed": true
      },
      "source": [
        "# write back to the lake\r\n",
        "dfDayAct.write.format('parquet').mode('overwrite').save(stage3 + '/test_s3_hybrid/dayActivity')\r\n",
        "dfYearAct.write.format('parquet').mode('overwrite').save(stage3 + '/test_s3_hybrid/yearActivity')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Load to Spark DB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "spark2",
              "session_id": 17,
              "statement_id": 26,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2021-08-25T17:24:30.1997374Z",
              "session_start_time": null,
              "execution_start_time": "2021-08-25T17:26:04.193578Z",
              "execution_finish_time": "2021-08-25T17:26:09.4974044Z"
            },
            "text/plain": "StatementMeta(spark2, 17, 26, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": []
        }
      ],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "collapsed": true
      },
      "source": [
        "# Create spark db to allow for access to the data in the delta-lake via SQL on-demand.\r\n",
        "# This is only creating metadata for SQL on-demand, pointing to the data in the delta-lake.\r\n",
        "# This also makes it possible to connect in Power BI via the azure sql data source connector.\r\n",
        "def create_spark_db(db_name, source_path):\r\n",
        "    spark.sql(f'CREATE DATABASE IF NOT EXISTS {db_name}')\r\n",
        "    spark.sql(f\"DROP TABLE IF EXISTS {db_name}.dayActivity\")\r\n",
        "    spark.sql(f\"DROP TABLE IF EXISTS {db_name}.yearActivity\")\r\n",
        "    spark.sql(f\"create table if not exists {db_name}.dayActivity using PARQUET location '{source_path}/dayActivity'\")\r\n",
        "    spark.sql(f\"create table if not exists {db_name}.yearActivity using PARQUET location '{source_path}/yearActivity'\")\r\n",
        "    \r\n",
        "create_spark_db('test_s3_hybrid', stage3 + '/test_s3_hybrid')"
      ]
    }
  ]
}