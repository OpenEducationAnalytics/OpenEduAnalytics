{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Digital Activity Schema Standard Class Notebook\r\n",
        "\r\n",
        "This schema standardization class notebook outlines the 3 necessary functions for processing module schemas into the OEA digital activity schema standard.\r\n",
        "\r\n",
        "These 3 functions are:\r\n",
        "\r\n",
        " - get_digital_activity_schema - which defines what the digital activity standard consists of, and how to map other data sources to this OEA standard.\r\n",
        " - reset_digital_activity_processing - which deletes the \"digital_activity\" folder from stage 2p, allowing you to start over the schema standardization process. \r\n",
        " - process_digital_activity - which takes in the user-defined schema mapping and source folder, while executing the standardization process to be re-written back to stage 2p.\r\n",
        "\r\n",
        " Any custom/additional data source schema mappings should be defined here."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DigitalActivity(BaseOEAModule):\r\n",
        "    \"\"\"\r\n",
        "    Currently, package class notebook only contains processing for stage2p data.\r\n",
        "     - Reads activity data from stage2p, writes the activity data schema/relationship mapping to stage2p again\r\n",
        "     - Then takes this mapping and generalized and method for writing to stage3p\r\n",
        "    \"\"\"\r\n",
        "\r\n",
        "    def __init__(self, source_folder='digital_activity'):\r\n",
        "        \r\n",
        "        BaseOEAModule.__init__(self, oea, source_folder)\r\n",
        "        \r\n",
        "        self.stage2p_digitalActivity = self.stage2p + 'digital_activity'\r\n",
        "\r\n",
        "        self.schemas['ActivityEvents'] = [['event_id', 'string', 'no-op'],\r\n",
        "                        ['event_type', 'string', 'no-op'],\r\n",
        "                        ['event_actor', 'string', 'no-op'],\r\n",
        "                        ['event_object', 'string', 'no-op'],\r\n",
        "                        ['event_eventTime', 'string', 'no-op'],\r\n",
        "                        ['entity_type', 'string', 'no-op'], \r\n",
        "                        ['softwareApplication_version', 'string', 'no-op'], \r\n",
        "                        ['generated_aggregateMeasure_metric_timeOnTask', 'string', 'no-op'], \r\n",
        "                        ['generated_aggregateMeasure_metric_numAccess', 'string', 'no-op'],\r\n",
        "                        ['generated_aggregateMeasure_metric_used', 'string', 'no-op'],\r\n",
        "                        ['generated_aggregateMeasure_metric_activityReportPeriod', 'string', 'no-op']]\r\n",
        "\r\n",
        "        self.schemasDetail = {}\r\n",
        "        self.schemasDetail['ActivityEvents'] = [['schema_source', 'https://www.imsglobal.org/spec/caliper/v1p2#tooluseevent'],\r\n",
        "                        ['event_id','unique ID used as a signal key'],\r\n",
        "                        ['event_type', 'type of activity event'],\r\n",
        "                        ['event_actor', 'student or teacher that created the signal'],\r\n",
        "                        ['event_object', 'entity that comprises the object of the interaction'],\r\n",
        "                        ['event_eventTime', 'date/timestamp of the activity signal'],\r\n",
        "                        ['entity_type', 'value that describes the properties of the user agent hosting this SoftwareApplication.'],\r\n",
        "                        ['softwareApplication_version', 'value that describes the properties of the user agent hosting this SoftwareApplication.'],\r\n",
        "                        ['generated_aggregateMeasure_metric_timeOnTask', 'time on task in seconds'],\r\n",
        "                        ['generated_aggregateMeasure_metric_numAccess', 'number of accesses'], \r\n",
        "                        ['generated_aggregateMeasure_metric_used', 'used true or false'], \r\n",
        "                        ['generated_aggregateMeasure_metric_activityReportPeriod', 'activity data collected is reported over this number of days']]\r\n",
        "\r\n",
        "\r\n",
        "    def get_digital_activity_schema(self):\r\n",
        "        \"\"\" Get information on digital activity schema\r\n",
        "            - needed to align schemas to activity data source\r\n",
        "        \"\"\"\r\n",
        "        print(\"OEA Standard Digital Activity Schema:\\n\")\r\n",
        "        \r\n",
        "        print(\"Columns and data types:\\n\")\r\n",
        "        for var in self.schemas['ActivityEvents']:\r\n",
        "            print(var)\r\n",
        "        \r\n",
        "        print(\"\\nColumn descriptions:\\n\")\r\n",
        "        for var in self.schemasDetail['ActivityEvents']:\r\n",
        "            print(var)\r\n",
        "\r\n",
        "\r\n",
        "    def reset_digital_activity_processing(self):\r\n",
        "        \"\"\" Resets all data. This is intended for use during initial testing - use with caution.\r\n",
        "            - deletes the delta table at stage2/digital_activity\r\n",
        "        \"\"\"\r\n",
        "        oea.rm_if_exists(self.stage2p_digitalActivity)\r\n",
        "        logger.info(f\"Deleted {self.stage2p_digitalActivity}\")\r\n",
        "\r\n",
        "    \r\n",
        "    def process_digital_activity(self,source_path, schemaMapping):\r\n",
        "        \"\"\" Processes digital activity data into standardized table with standard activity schema.\r\n",
        "            - path: Storage locatoin and directory name (ie stage2p/M365/TechActivity_pseudo)\r\n",
        "            - schemaMapping: mapping of table columns to ActivityEvents schema, NULL if no mapping provided\r\n",
        "        \"\"\"\r\n",
        "        from pyspark.sql.functions import lit\r\n",
        "        \r\n",
        "        logger.info(\"Processing digital activity data from: \" + source_path)\r\n",
        "      \r\n",
        "        dfActivity = oea.load_delta(source_path)\r\n",
        "\r\n",
        "        df = spark.createDataFrame(schemaMapping, schema = [\"schema\", \"source\"])\r\n",
        "        df = df.na.drop(\"any\")\r\n",
        "\r\n",
        "        obj = df.filter(df['schema'] == \"event_object\").collect()[0][1]\r\n",
        "        dfCols = df.filter(df['schema'] != \"event_object\")\r\n",
        "\r\n",
        "        colList = dfCols.select('source').collect()\r\n",
        "        colList = [col.source for col in colList]\r\n",
        "\r\n",
        "        df = dfActivity.select(colList)\r\n",
        "\r\n",
        "        # rename source column to be schema column\r\n",
        "        for row in dfCols.rdd.collect():\r\n",
        "            schemaCol = row[0]\r\n",
        "            sourceCol = row[1]\r\n",
        "            df = df.withColumnRenamed(sourceCol, schemaCol)\r\n",
        "            df = df.withColumn(schemaCol, df[schemaCol].cast(StringType()))\r\n",
        "                    \r\n",
        "        df = df.withColumn('event_object', F.lit(obj))\r\n",
        "        df = df.withColumn('year', F.year(F.col('event_eventTime'))).withColumn('month', F.month(F.col('event_eventTime')))\r\n",
        "        #df.write.save(self.stage2p, format='delta', mode='append', partitionBy=['year', 'month'], mergeSchema='true')\r\n",
        "        df.write.save(oea.path('stage2p', directory_path=\"digital_activity\"), format='delta', mode='append', partitionBy=['year', 'month'], mergeSchema='true')\r\n",
        "        #df.write.save(oea.path(self.stage2p_digitalActivity, format='delta', mode='append', partitionBy=['year', 'month'], mergeSchema='true')\r\n",
        "        \r\n",
        "        logger.info(\"Complete processing from: \" + source_path)\r\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "synapse_pyspark",
      "display_name": "python"
    },
    "language_info": {
      "name": "python"
    },
    "description": null,
    "save_output": true,
    "synapse_widget": {
      "version": "0.1",
      "state": {}
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}